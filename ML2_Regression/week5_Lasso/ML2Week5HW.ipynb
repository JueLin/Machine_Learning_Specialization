{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from math import log, sqrt\n",
    "from sklearn import linear_model  # using scikit-learn\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtype_dict = {'bathrooms':float, 'waterfront':int, 'sqft_above':int, 'sqft_living15':float, 'grade':int, 'yr_renovated':int, 'price':float, 'bedrooms':float, 'zipcode':str, 'long':float, 'sqft_lot15':float, 'sqft_living':float, 'floors':float, 'condition':int, 'lat':float, 'date':str, 'sqft_basement':int, 'yr_built':int, 'id':str, 'sqft_lot':int, 'view':int}\n",
    "\n",
    "sales = pd.read_csv('hw1/kc_house_data.csv', dtype=dtype_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sales['sqft_living_sqrt'] = sales['sqft_living'].apply(sqrt)\n",
    "sales['sqft_lot_sqrt'] = sales['sqft_lot'].apply(sqrt)\n",
    "sales['bedrooms_square'] = sales['bedrooms']*sales['bedrooms']\n",
    "sales['floors_square'] = sales['floors']*sales['floors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=500.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=True, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features = ['bedrooms', 'bedrooms_square',\n",
    "            'bathrooms',\n",
    "            'sqft_living', 'sqft_living_sqrt',\n",
    "            'sqft_lot', 'sqft_lot_sqrt',\n",
    "            'floors', 'floors_square',\n",
    "            'waterfront', 'view', 'condition', 'grade',\n",
    "            'sqft_above',\n",
    "            'sqft_basement',\n",
    "            'yr_built', 'yr_renovated']\n",
    "\n",
    "model_all = linear_model.Lasso(alpha=5e2, normalize=True) # set parameters\n",
    "model_all.fit(sales[all_features], sales['price']) # learn weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sqft_living', 'view', 'grade']\n"
     ]
    }
   ],
   "source": [
    "print [all_features[i] for i in range(len(all_features)) if model_all.coef_[i] != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testing = pd.read_csv('hw1/wk3_kc_house_test_data.csv', dtype=dtype_dict)\n",
    "training = pd.read_csv('hw1/wk3_kc_house_train_data.csv', dtype=dtype_dict)\n",
    "validation = pd.read_csv('hw1/wk3_kc_house_valid_data.csv', dtype=dtype_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testing['sqft_living_sqrt'] = testing['sqft_living'].apply(sqrt)\n",
    "testing['sqft_lot_sqrt'] = testing['sqft_lot'].apply(sqrt)\n",
    "testing['bedrooms_square'] = testing['bedrooms']*testing['bedrooms']\n",
    "testing['floors_square'] = testing['floors']*testing['floors']\n",
    "\n",
    "training['sqft_living_sqrt'] = training['sqft_living'].apply(sqrt)\n",
    "training['sqft_lot_sqrt'] = training['sqft_lot'].apply(sqrt)\n",
    "training['bedrooms_square'] = training['bedrooms']*training['bedrooms']\n",
    "training['floors_square'] = training['floors']*training['floors']\n",
    "\n",
    "validation['sqft_living_sqrt'] = validation['sqft_living'].apply(sqrt)\n",
    "validation['sqft_lot_sqrt'] = validation['sqft_lot'].apply(sqrt)\n",
    "validation['bedrooms_square'] = validation['bedrooms']*validation['bedrooms']\n",
    "validation['floors_square'] = validation['floors']*validation['floors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l1_penalty = np.logspace(1, 7, num=13)\n",
    "rss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.982133273e+14\n",
      "3.99041900253e+14\n",
      "4.29791604073e+14\n",
      "4.63739831045e+14\n",
      "6.45898733634e+14\n",
      "1.22250685943e+15\n",
      "1.22250685943e+15\n",
      "1.22250685943e+15\n",
      "1.22250685943e+15\n",
      "1.22250685943e+15\n",
      "1.22250685943e+15\n",
      "1.22250685943e+15\n",
      "1.22250685943e+15\n",
      "l1 penaly achieving minimum validation error = 10.0\n"
     ]
    }
   ],
   "source": [
    "for l1 in l1_penalty:\n",
    "    model = linear_model.Lasso(alpha=l1, normalize=True)\n",
    "    model.fit(training[all_features], training['price'])\n",
    "    rss.append(np.sum((validation['price'] - model.predict(validation[all_features]))**2))\n",
    "    print rss[-1]\n",
    "print 'l1 penaly achieving minimum validation error = ' + str(l1_penalty[rss.index(min(rss))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "best_l1 = l1_penalty[rss.index(min(rss))]\n",
    "best_model = linear_model.Lasso(alpha=best_l1, normalize=True)\n",
    "best_model.fit(training[all_features], training['price'])\n",
    "print str(np.count_nonzero(best_model.coef_) + np.count_nonzero(best_model.intercept_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15, 15, 15, 15, 13, 12, 11, 10, 7, 6, 6, 6, 5, 3, 3, 2, 1, 1, 1, 1]\n",
      "l1 max = 263.665089873 l1 min = 127.42749857\n"
     ]
    }
   ],
   "source": [
    "num_nonzero = []\n",
    "l1_penalty = np.logspace(1, 4, num=20)\n",
    "max_nonzeros = 7\n",
    "for l1 in l1_penalty:\n",
    "    model = linear_model.Lasso(alpha=l1, normalize=True)\n",
    "    model.fit(training[all_features], training['price'])\n",
    "    num_nonzero.append(np.count_nonzero(model.coef_) + np.count_nonzero(model.intercept_))\n",
    "print num_nonzero\n",
    "l1_penalty_max = [l1_penalty[i] for i in range(len(l1_penalty)) if num_nonzero[i] < max_nonzeros][0]\n",
    "l1_penalty_min = [l1_penalty[i] for i in range(len(l1_penalty)) if num_nonzero[i] > max_nonzeros][-1]\n",
    "print 'l1 max = ' + str(l1_penalty_max) + ' l1 min = ' + str(l1_penalty_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    10.             14.38449888     20.69138081     29.76351442\n",
      "     42.81332399     61.58482111     88.58667904    127.42749857\n",
      "    183.29807108    263.66508987    379.26901907    545.55947812\n",
      "    784.75997035   1128.83789168   1623.77673919   2335.72146909\n",
      "   3359.81828628   4832.93023857   6951.92796178  10000.        ]\n"
     ]
    }
   ],
   "source": [
    "print l1_penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min rss = 4.40037365263e+14 best l1 penalty = 156.109096739\n"
     ]
    }
   ],
   "source": [
    "l1_penalty = np.linspace(l1_penalty_min,l1_penalty_max,20)\n",
    "num_nonzero = []\n",
    "rss = []\n",
    "for l1 in l1_penalty:\n",
    "    model = linear_model.Lasso(alpha=l1, normalize=True)\n",
    "    model.fit(training[all_features], training['price'])\n",
    "    rss.append(np.sum((validation['price'] - model.predict(validation[all_features]))**2))\n",
    "    num_nonzero.append(np.count_nonzero(model.coef_) + np.count_nonzero(model.intercept_))\n",
    "\n",
    "min_rss = min([rss[i] for i in range(len(l1_penalty)) if num_nonzero[i] == max_nonzeros])\n",
    "best_l1_penalty = l1_penalty[rss.index(min_rss)]\n",
    "print 'min rss = ' + str(min_rss) + ' best l1 penalty = ' + str(best_l1_penalty) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bathrooms', 'sqft_living', 'waterfront', 'view', 'grade', 'yr_built']\n",
      "4422190.27912\n"
     ]
    }
   ],
   "source": [
    "model = linear_model.Lasso(alpha=best_l1_penalty, normalize=True)\n",
    "model.fit(training[all_features], training['price'])\n",
    "print [all_features[i] for i in range(len(all_features))  if model.coef_[i] != 0 ]\n",
    "print model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtype_dict = {'bathrooms':float, 'waterfront':int, 'sqft_above':int, 'sqft_living15':float, 'grade':int, 'yr_renovated':int, 'price':float, 'bedrooms':float, 'zipcode':str, 'long':float, 'sqft_lot15':float, 'sqft_living':float, 'floors':float, 'condition':int, 'lat':float, 'date':str, 'sqft_basement':int, 'yr_built':int, 'id':str, 'sqft_lot':int, 'view':int}\n",
    "\n",
    "data = pd.read_csv('hw2/kc_house_data.csv', dtype=dtype_dict)\n",
    "train = pd.read_csv('hw2/kc_house_train_data.csv', dtype=dtype_dict)\n",
    "test = pd.read_csv('hw2/kc_house_test_data.csv',dtype=dtype_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_numpy_data(data, features, output):\n",
    "    data['constant'] = 1\n",
    "    features = ['constant'] + features\n",
    "    output_np = data[output]\n",
    "    output_np = output_np.as_matrix()\n",
    "    data_np = data.as_matrix(features)\n",
    "    return (data_np, output_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_output(data_np, weights):\n",
    "    predictions = np.dot(data_np, weights)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_features(features):\n",
    "    norms = np.linalg.norm(features, axis=0)\n",
    "    normalized_features = features/norms\n",
    "    return (normalized_features, norms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_rho_i(data_np, output_np, weights, i):\n",
    "    predictions = np.dot(data_np, weights)\n",
    "    ro_i = np.dot(data_np[:, i], (output_np - predictions + weights[i]*data_np[:, i]))\n",
    "    return ro_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1 && Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "initial_weight = [1, 4, 1]\n",
    "features = ['sqft_living', 'bedrooms']\n",
    "output = 'price'\n",
    "\n",
    "data_np, output_np = get_numpy_data(data, features, output)\n",
    "normalized_data_np, norms = normalize_features(data_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "higher bound of lambda = 175878941.647\n",
      "lower bound of lambda 161933397.332\n"
     ]
    }
   ],
   "source": [
    "print 'higher bound of lambda = ' + str(2*compute_rho_i(normalized_data_np, output_np, initial_weight, 1))\n",
    "print 'lower bound of lambda ' + str(2*compute_rho_i(normalized_data_np, output_np, initial_weight, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def lasso_coordinate_descent_step(i, feature_matrix, output, weights, l1_penalty):\n",
    "    # compute prediction\n",
    "    # prediction = ...\n",
    "    # compute ro[i] = SUM[ [feature_i]*(output - prediction + weight[i]*[feature_i]) ]\n",
    "    ro_i = compute_rho_i(feature_matrix, output, weights, i)\n",
    "    \n",
    "    if i == 0: # intercept -- do not regularize\n",
    "        new_weight_i = ro_i\n",
    "    elif ro_i < -l1_penalty/2.:\n",
    "        new_weight_i = ro_i + l1_penalty/2\n",
    "    elif ro_i > l1_penalty/2.:\n",
    "        new_weight_i = ro_i - l1_penalty/2\n",
    "    else:\n",
    "        new_weight_i = 0.\n",
    "    \n",
    "    return new_weight_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.425558846691\n"
     ]
    }
   ],
   "source": [
    "# should print 0.425558846691\n",
    "import math\n",
    "print lasso_coordinate_descent_step(1, np.array([[3./math.sqrt(13),1./math.sqrt(10)],\n",
    "                   [2./math.sqrt(13),3./math.sqrt(10)]]), np.array([1., 1.]), np.array([1., 4.]), 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lasso_cyclical_coordinate_descent(feature_matrix, output, weights, l1_penalty, tolerance):\n",
    "    converged = False\n",
    "    while not converged:\n",
    "        change_in_weight = []\n",
    "        for i in range(len(weights)):\n",
    "            old_weight = weights[i]\n",
    "            weights[i] = lasso_coordinate_descent_step(i, feature_matrix, output, weights, l1_penalty)\n",
    "            change_in_weight.append(abs(weights[i] - old_weight))\n",
    "        if max(change_in_weight) < tolerance:\n",
    "            converged = True\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rss = 1.63049247672e+15\n",
      "[21624997.959519144, 63157247.207889512, 0.0]\n"
     ]
    }
   ],
   "source": [
    "features = ['sqft_living', 'bedrooms']\n",
    "output = 'price'\n",
    "\n",
    "data_np, output_np = get_numpy_data(data, features, output)\n",
    "normalized_data_np, norms = normalize_features(data_np)\n",
    "\n",
    "initial_weights = [0, 0, 0]\n",
    "l1_penalty = 1e7\n",
    "tolerance = 1.0\n",
    "\n",
    "lasso_model = lasso_cyclical_coordinate_descent(normalized_data_np, output_np, initial_weights, l1_penalty, tolerance)\n",
    "\n",
    "print 'rss = ' + str(np.sum((output_np - predict_output(normalized_data_np, lasso_model))**2))\n",
    "print lasso_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sqft_living', 'waterfront', 'view']\n",
      "[]\n",
      "['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors', 'waterfront', 'view', 'condition', 'grade', 'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated']\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('hw2/kc_house_train_data.csv', dtype=dtype_dict)\n",
    "test = pd.read_csv('hw2/kc_house_test_data.csv', dtype=dtype_dict)\n",
    "\n",
    "features = ['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors', 'waterfront', 'view', 'condition', 'grade', 'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated']\n",
    "output = 'price'\n",
    "\n",
    "train_np, train_output_np = get_numpy_data(train, features, output)\n",
    "normalized_train_np, norms = normalize_features(train_np)\n",
    "\n",
    "initial_weights = np.zeros(len(features)+1)\n",
    "l1_penalty = 1e7\n",
    "tolerance = 1.0\n",
    "\n",
    "weights1e7 = lasso_cyclical_coordinate_descent(normalized_train_np, train_output_np, initial_weights, l1_penalty, tolerance)\n",
    "print [features[i] for i in range(len(features)) if weights1e7[i+1] != 0]\n",
    "\n",
    "initial_weights = np.zeros(len(features)+1)\n",
    "l1_penalty = 1e8\n",
    "weights1e8 = lasso_cyclical_coordinate_descent(normalized_train_np, train_output_np, initial_weights, l1_penalty, tolerance)\n",
    "print [features[i] for i in range(len(features)) if weights1e8[i+1] != 0]\n",
    "\n",
    "initial_weights = np.zeros(len(features)+1)\n",
    "l1_penalty = 1e4\n",
    "tolerance = 5e5\n",
    "weights1e4 = lasso_cyclical_coordinate_descent(normalized_train_np, train_output_np, initial_weights, l1_penalty, tolerance)\n",
    "print [features[i] for i in range(len(features)) if weights1e4[i+1] != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161.317457646\n"
     ]
    }
   ],
   "source": [
    "normalized_weights1e7 = weights1e7/norms\n",
    "normalized_weights1e8 = weights1e8/norms\n",
    "normalized_weights1e4 = weights1e4/norms\n",
    "\n",
    "print normalized_weights1e7[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_np, test_out_np = get_numpy_data(test, features, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rss of l1 = 1e7 is: 2.7596207592e+14\n",
      "rss of l1 = 1e8 is: 5.37166151497e+14\n",
      "rss of l1 = 1e4 is: 2.28459958971e+14\n"
     ]
    }
   ],
   "source": [
    "print 'rss of l1 = 1e7 is: ' + str(np.sum((test_out_np - predict_output(test_np, normalized_weights1e7))**2))\n",
    "print 'rss of l1 = 1e8 is: ' + str(np.sum((test_out_np - predict_output(test_np, normalized_weights1e8))**2))\n",
    "print 'rss of l1 = 1e4 is: ' + str(np.sum((test_out_np - predict_output(test_np, normalized_weights1e4))**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
